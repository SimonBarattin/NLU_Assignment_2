{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import conll\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_doc(path):\n",
    "    file = conll.read_corpus_conll(path, ' ')\n",
    "    for tst in file:\n",
    "        if tst[0][0] == '-DOCSTART-':\n",
    "            file.remove(tst)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that allows us to change the spacy representation, so that we can actually compare the results with the conll ones\n",
    "def changeRep(token):\n",
    "    if token.ent_iob_ != 'O':\n",
    "        if token.ent_type_ == 'PERSON':\n",
    "            return token.ent_iob_ + '-PER'\n",
    "        if token.ent_type_ == 'ORG':\n",
    "            return token.ent_iob_ + '-ORG'\n",
    "        if (token.ent_type_ == 'GPE') or (token.ent_type_ == 'LOC') or (token.ent_type_ == 'FAC'):\n",
    "            return token.ent_iob_ + '-LOC'\n",
    "        if token.ent_type == '':\n",
    "                return 'O'\n",
    "        else:\n",
    "            return token.ent_iob_ + '-MISC'\n",
    "    else:\n",
    "        return token.ent_iob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(refs, hyps):\n",
    "    pred = []\n",
    "    true = []\n",
    "    for ent in refs:\n",
    "        true.append(ent[0][1])\n",
    "    for ent in hyps:\n",
    "        pred.append(ent[0][1])\n",
    "    res = classification_report(true, pred)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent(sent):\n",
    "    res = []\n",
    "    token = ''\n",
    "    for t in sent:\n",
    "        if t.whitespace_:\n",
    "            token += t.text\n",
    "            label = changeRep(t)\n",
    "            res.append((token, label))\n",
    "            token = ''\n",
    "        else:\n",
    "            token += t.text\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain the data from conll2003 dataset and remove the -DOCSTART- entries\n",
    "def evaluate(path):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    file = remove_doc(path)\n",
    "    refs = [[(text, iob) for text, pos, _, iob in sent] for sent in file]\n",
    "    hyps = []\n",
    "    for row in file:\n",
    "        text = ''.join(t[0]+' ' for t in row)\n",
    "        doc = nlp(text)\n",
    "        tokenized = get_sent(doc)\n",
    "        hyps.append(tokenized)\n",
    "\n",
    "    accuracies = get_stats(refs, hyps)\n",
    "    print(accuracies)\n",
    "\n",
    "    #run the conll evaluation function to obtain the chunk level accuracies\n",
    "    results = conll.evaluate(refs, hyps)\n",
    "\n",
    "    pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "    print('\\t1.2 - report CoNLL chunk-level performance (per class and total)\\n')\n",
    "    print(pd_tbl.round(decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ents(sent):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(sent)\n",
    "    groups = []\n",
    "    ne = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        temp = []\n",
    "        for e in chunk.ents:\n",
    "            if e not in ne:\n",
    "                ne.append(e)\n",
    "                temp.append(e.label_)\n",
    "        if ne and len(temp) != 0:\n",
    "            groups.append(temp)\n",
    "    for ent in doc.ents:\n",
    "        if ent not in ne:\n",
    "            groups.append([ent.label_])        \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequencies(path):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    file = remove_doc(path)\n",
    "    groups = {}\n",
    "    for row in file[:100]:\n",
    "        sent = ''.join(t[0]+' ' for t in row)\n",
    "        g = group_ents(sent)\n",
    "        for group in g:\n",
    "            st = ''\n",
    "            for x in group:\n",
    "                st += x + ' '\n",
    "            if st not in groups:\n",
    "                groups[st] = 1\n",
    "            else:\n",
    "                groups[st] += 1\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head(dep, token):\n",
    "    if token.dep_ == 'compound':\n",
    "        dep.append(token)\n",
    "        get_head(dep, token.head)\n",
    "    else:\n",
    "        dep.append(token)\n",
    "    return dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_seg(sent):\n",
    "    res = []\n",
    "    compounds = []\n",
    "    skip = []\n",
    "    ent_c = []\n",
    "    indexes = []\n",
    "    for t in sent:\n",
    "        if t.dep_ == 'compound':\n",
    "            compounds.append(get_head([], t))\n",
    "    for span in compounds:\n",
    "        indexes.append([t.i for t in span])\n",
    "        for t in span:            \n",
    "            skip.append(t.i)\n",
    "    for t in sent:\n",
    "        if (not t.i in skip):\n",
    "            indexes.append([t.i])\n",
    "    indexes = sorted(indexes, key=lambda x: x[0])\n",
    "    for ind in indexes:\n",
    "        if len(ind) == 1:\n",
    "            ent_c.append(sent[ind[0]:ind[0]+1])\n",
    "        else:\n",
    "            ent_c.append(sent[ind[0]:ind[-1]+1])\n",
    "    return ent_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------#1-----------------------------\n",
      "\n",
      "Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
      "\t1.1 - report token-level performance (per class and total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\NLU\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\miniconda3\\envs\\NLU\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\miniconda3\\envs\\NLU\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.60      0.47      0.52       407\n",
      "      B-MISC       0.27      0.58      0.37       116\n",
      "       B-ORG       0.53      0.22      0.31       747\n",
      "       B-PER       0.62      0.55      0.58       298\n",
      "      I-MISC       0.00      0.00      0.00         0\n",
      "       I-ORG       0.00      0.00      0.00         0\n",
      "       I-PER       0.00      0.00      0.00         0\n",
      "           O       0.71      0.87      0.78      1885\n",
      "\n",
      "    accuracy                           0.64      3453\n",
      "   macro avg       0.34      0.34      0.32      3453\n",
      "weighted avg       0.64      0.64      0.62      3453\n",
      "\n",
      "\t1.2 - report CoNLL chunk-level performance (per class and total)\n",
      "\n",
      "           p      r      f     s\n",
      "LOC    0.749  0.671  0.708  1668\n",
      "MISC   0.111  0.546  0.184   702\n",
      "PER    0.774  0.609  0.681  1617\n",
      "ORG    0.464  0.276  0.346  1661\n",
      "total  0.408  0.521  0.458  5648\n",
      "\n",
      "-----------------------------#2-----------------------------\n",
      "\n",
      "Test sentence: Apple's Steve Jobs died in 2011 in Palo Alto, California.\n",
      " Result: [['ORG', 'PERSON'], ['GPE'], ['GPE'], ['DATE']]\n",
      "Frequencies:\n",
      "\n",
      "CARDINAL  :  67\n",
      "GPE  :  65\n",
      "PERSON  :  62\n",
      "DATE  :  22\n",
      "ORG  :  21\n",
      "TIME  :  15\n",
      "CARDINAL PERSON  :  10\n",
      "NORP  :  8\n",
      "ORDINAL  :  7\n",
      "EVENT  :  6\n",
      "GPE GPE  :  2\n",
      "NORP PERSON  :  1\n",
      "GPE PERSON  :  1\n",
      "DATE EVENT  :  1\n",
      "ORDINAL NORP  :  1\n",
      "CARDINAL GPE  :  1\n",
      "GPE PERSON CARDINAL  :  1\n",
      "LAW  :  1\n",
      "\n",
      "-----------------------------#3-----------------------------\n",
      "\n",
      "Fix segmentation errors.\n",
      "\n",
      "Test sentence: \"Apple's Steve Jobs died in 2011 in Palo Alto, California.\"\n",
      "Apple :  B-ORG\n",
      "'s :  O\n",
      "Steve :  B-PERSON\n",
      "Jobs :  I-PERSON\n",
      "died :  O\n",
      "in :  O\n",
      "2011 :  B-DATE\n",
      "in :  O\n",
      "Palo :  B-GPE\n",
      "Alto :  I-GPE\n",
      ", :  O\n",
      "California :  B-GPE\n",
      ". :  O\n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------#1-----------------------------\\n')\n",
    "print('Evaluate spaCy NER on CoNLL 2003 data (provided)')\n",
    "print('\\t1.1 - report token-level performance (per class and total)\\n')\n",
    "evaluate('src/conll2003/test.txt')\n",
    "print('\\n-----------------------------#2-----------------------------\\n')\n",
    "tst = \"Apple's Steve Jobs died in 2011 in Palo Alto, California.\"\n",
    "print(\"Test sentence: Apple's Steve Jobs died in 2011 in Palo Alto, California.\\n\", f'Result: {group_ents(tst)}')\n",
    "frequencies = get_frequencies('src/conll2003/test.txt')\n",
    "sort = {k: v for k, v in sorted(frequencies.items(), key=lambda item: item[1], reverse=True)}\n",
    "print('Frequencies:\\n')\n",
    "for y in sort:\n",
    "    print(y,': ',sort[y])\n",
    "print('\\n-----------------------------#3-----------------------------\\n')\n",
    "    print('Fix segmentation errors.\\n')\n",
    "print('Test sentence: \"Apple\\'s Steve Jobs died in 2011 in Palo Alto, California.\"')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(tst)\n",
    "comp = compound_seg(doc)\n",
    "for c in comp:\n",
    "    for x in c:\n",
    "        print(x.text, ': ', (f'{x.ent_iob_}-{x.ent_type_}' if x.ent_iob_ != 'O' else x.ent_iob_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
